import os
from pyexpat import model
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"
import torch
import cv2
import re
import numpy as np
import torch.nn as nn
import random
import torch.nn.functional as F
from torch.utils.data import DataLoader,Dataset

class SiameseNetwork(nn.Module):
    #孿生網路
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn = nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=3),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),

                nn.Conv2d(16, 32, kernel_size=2),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),

                nn.Conv2d(32, 64, kernel_size=2),
                nn.ReLU(inplace=True)
        )

        self.fc1 = nn.Sequential(
                nn.Linear(14*14*64, 128)
        )

        self.fc2 = nn.Sequential(
                nn.Linear(128, 1),
                nn.Sigmoid()
        )

    def forward_once(self, x):
        output = self.cnn(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        output = torch.abs(output1 - output2)
        output = self.fc2(output)
        return output


#引入模型
net = torch.load('C:/Users/jack8/Desktop/Mid_Project/model_SiameseNet10.pth', map_location=torch.device('cpu'))


def read_directory(files, w, h):
    idx = 0
    array_of_img = {}
    for f_name in files:
        array_of_img[idx] = []
        for img_name in os.listdir(path + '/' + f_name):
            img = cv2.imread(path + '/' + f_name + '/' + img_name)
            img = cv2.resize(img, (w, h))
            img = img.transpose((2, 0, 1))
            array_of_img[idx].append(img)
        idx += 1
    return array_of_img

path = 'C:/Users/jack8/Desktop/Mid_Project/test'
files = os.listdir(path)
w = 64 #寬
h = 64 #高
array_of_img = read_directory(files, w, h)

class_num = 3 #類別數
each_class = 7 #SupportSet各類別樣本數
test_num = 13 #test各類別樣本數

suppset_size = class_num * each_class #SupportSet總樣本數
testset_size = class_num * test_num #TestSet總樣本數

def get_data(suppset_size , testset_size, class_num, each_class):

    pick_img = array_of_img[0][0]
    #提取圖片大小
    dim1 = pick_img.shape[1]
    dim2 = pick_img.shape[2]

    count = 0
    #初始化一nparray[total_sample, dim1, dim2]
    x_suppset = np.zeros([suppset_size, 3, dim1, dim2])
    y_label = np.zeros([suppset_size, 1])
 
    for i in range(class_num):
        for j in range(each_class):
 
            #讀取圖片
            img_supp = array_of_img[i][j]
 
            #儲存至初始化之nparray
            x_suppset[count, :, :, :] = img_supp
 
            #建立標籤
            y_label[count] = i+(class_num+2)
            count += 1
    
    count = 0
    x_testset = np.zeros([testset_size, 3, dim1, dim2])
    y_testlabel = np.zeros([testset_size, 1])

    for i in range(class_num):
        for j in range(test_num):
            
            #讀取圖片
            img_test = array_of_img[i][j+each_class]
 
            #儲存至初始化之nparray
            x_testset[count, :, :, :] = img_test

            #建立標籤
            y_testlabel[count] = i+(class_num+2)
            count += 1
 

    supp_data = x_suppset/255
    supp_label = y_label
    test_data = x_testset/255
    test_label = y_testlabel
 
    return supp_data, supp_label, test_data, test_label

def shuffle_data(t_data, t_label):
    #資料重新排序
    img_test = t_data[:]
    label_test = t_label

    index_t = [i for i in range(len(img_test))] 
    random.shuffle(index_t)
    img_test = img_test[index_t]
    label_test = label_test[index_t]

    return img_test, label_test

supp_data, supp_label, test_data, test_label = get_data(suppset_size , testset_size, class_num, each_class)
img_test, label_test = shuffle_data(test_data, test_label)

class TestdataSet(Dataset): #TestSet資料整理

    def __init__(self, test, test_labels):
        self.img1_data = test
        self.label1_data = test_labels
        self.len = len(test)

    def __getitem__(self,index):
        return self.img1_data[index], self.label1_data[index]

    def __len__(self):
        return self.len

class SuppdataSet(Dataset): #SupportSet資料整理

    def __init__(self, supports, supp_labels):
        self.img2_data = supports
        self.label2_data = supp_labels
        self.len = len(supp_labels)

    def __getitem__(self,index):
        return self.img2_data[index], self.label2_data[index]

    def __len__(self):
        return self.len

class ImgSet(Dataset): #SupportSet資料整理

    def __init__(self, imgset):
        self.img3_data = imgset
        self.len = len(imgset)

    def __getitem__(self,index):
        return self.img3_data[index]

    def __len__(self):
        return self.len

supp_dataset = SuppdataSet(supports=supp_data, supp_labels=supp_label)
supp_dataloader = DataLoader(supp_dataset, shuffle=False, batch_size=1)

test_dataset = TestdataSet(test=img_test, test_labels=label_test)
test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=1)



#測試
net.eval()
correct_v = 0

with torch.no_grad():
    dataiter0 = iter(test_dataloader) #test迭代
    dataiter1 = iter(supp_dataloader) #SupportSet迭代

    for i in range(testset_size):
        
        x0,label_t = next(dataiter0)
        a = []
        b = []
        
        for j in range(suppset_size):
            try:
                x1,label1 = next(dataiter1)

            except:
                # 删除迭代器iter_test
                del dataiter1
                dataiter1 = iter(supp_dataloader)
                x1,label1 = next(dataiter1)
            output = net(x0.float(), x1.float())
            a.append(output)
        for k in range(0,suppset_size,each_class):
            right = 0
            for z in range(k,k+each_class):
                if a[z] >= 0.5:
                    right += 1
            b.append(right)
        

        pred = np.argmax(b) #找出最大值之位置
        if pred+class_num+2 == np.array(label_t):  #判斷是否與真實標籤相同
            correct_v += 1 #正確則加1
            accuracy = 100.*correct_v/testset_size #計算準確率

        # if supp_label[np.array(pred)] == np.array(label_t): #判斷是否與真實標籤相同
        #     correct_v += 1 #正確則加1
        #     accuracy = 100.*correct_v/testset_size #計算準確率

    print('Test accuracy:{:.2f}%'.format(accuracy))


def eval(x0):
    with torch.no_grad():
        dataiter1 = iter(supp_dataloader) #SupportSet迭代

        a = []
        b = []
        b_result = []

        for j in range(suppset_size):
            try:
                x1,label1 = next(dataiter1)
            except:
                # 删除迭代器iter_test
                del dataiter1
                dataiter1 = iter(supp_dataloader)
                x1,label1 = next(dataiter1)
            output = net(x0.float(), x1.float())
            a.append(output)
        for k in range(0,suppset_size,each_class):
            right = 0
            a_result=[]
            for z in range(k,k+each_class):
                if a[z] >= 0.5:
                    a_result.append(a[z])
                    right += 1
            b.append(right)
            b_result.append(a_result)

        pred = np.argmax(b) #找出最大值之位置
        accuracy = torch.mean(torch.tensor(b_result[pred]))

        # if pred+class_num+2 == np.array(label_t):  #判斷是否與真實標籤相同
        #     correct_v += 1 #正確則加1
        #     accuracy = 100.*correct_v/testset_size #計算準確率
        # print('Test accuracy:{:.2f}%'.format(accuracy*100))
    return (accuracy*100, files[pred])


def eval_imgs(x_img):
    num = len(x_img)
    pred_result = []
    with torch.no_grad():
        imgset_dataset = ImgSet(imgset=x_img)
        imgset_dataloader = DataLoader(imgset_dataset, shuffle=False, batch_size=1)
        dataiter0 = iter(imgset_dataloader) #test迭代
        dataiter1 = iter(supp_dataloader) #SupportSet迭代
        result = []
        pred_class = []
        for i in range(num):
            
            x0 = next(dataiter0)
            a = []
            b = []
            b_result = []
            
            for j in range(suppset_size):
                try:
                    x1,label1 = next(dataiter1)

                except:
                    # 删除迭代器iter_test
                    del dataiter1
                    dataiter1 = iter(supp_dataloader)
                    x1,label1 = next(dataiter1)
                output = net(x0.float(), x1.float())
                a.append(output)
            for k in range(0,suppset_size,each_class):
                right = 0
                a_result=[]
                for z in range(k,k+each_class):
                    if a[z] >= 0.5:
                        a_result.append(a[z])
                        right += 1
                b.append(right)
                b_result.append(a_result)
            

            pred = np.argmax(b) #找出最大值之位置
            # pred_class.append(pred)
            accuracy = torch.mean(torch.tensor(b_result[pred]))
            pred_result.append((accuracy, files[pred]))
            # result.append(accuracy)
        # acc_result = torch.mean(torch.tensor(b_result[pred]))
        

    return pred_result


def predict_img(image):
    img = cv2.resize(image, (w,h))
    img = img.transpose((2, 0, 1))
    x0 = img/255
    dim1 = x0.shape[1]
    dim2 = x0.shape[2]
    x_img = np.zeros([1, 3, dim1, dim2])
    x_img[:] = x0
    x_img = torch.tensor(x_img)
    # x0 = convert_to_float(img)
    label_t = "family"
    return eval(x_img)


# img = array_of_img[0][0]
# img = img.transpose((1, 2, 0))

# print(predict_img(img))


# for i in range(5):
#     img = array_of_img[2][i+2]
#     array_of_img[2][i+2] = img.transpose((1, 2, 0))

def predict_imgs(images):
    reulst_list = []
    img_set = []
    x = images[0]
    dim1 = x.shape[0]
    dim2 = x.shape[1]
    count = 0
    x_img = np.zeros([len(images), 3, dim1, dim2])
    
    for i in images:
        img = cv2.resize(i, (w,h))
        img = img.transpose((2, 0, 1))
        x0 = img/255
        x_img[count, :, :, :] = x0
        count += 1
    x_img = torch.tensor(x_img) #確認型態

    # for img in x_img:
    #     reulst_list.append(img)
    # return reulst_list
    return eval_imgs(x_img)

# print(predict_imgs(array_of_img[2][2:7]))
import os
from pyexpat import model
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"
import torch
import torch.nn as nn
from torch import optim
from torch.utils.data import DataLoader,Dataset
import matplotlib.pyplot as plt
import numpy as np
import random
import cv2
from os.path import isfile, isdir, join

def show_plot(iteration,loss):
    #繪製損失變化圖
    plt.plot(iteration,loss)
    plt.show()

class SiameseNetwork(nn.Module):
    #孿生網路
    def __init__(self):
        super(SiameseNetwork, self).__init__()
        self.cnn = nn.Sequential(
                nn.Conv2d(3, 16, kernel_size=3),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),

                nn.Conv2d(16, 32, kernel_size=2),
                nn.ReLU(inplace=True),
                nn.MaxPool2d(2, 2),

                nn.Conv2d(32, 64, kernel_size=2),
                nn.ReLU(inplace=True)
        )

        self.fc1 = nn.Sequential(
                nn.Linear(14*14*64, 128)
        )

        self.fc2 = nn.Sequential(
                nn.Linear(128, 1),
                nn.Sigmoid()
                # nn.ReLU(inplace = True),
                # nn.Linear(64, 9),
                # nn.ReLU(inplace = True),
                # nn.Linear(9, 1)
        )

    def forward_once(self, x):
        output = self.cnn(x)
        output = output.view(output.size()[0], -1)
        output = self.fc1(output)
        return output

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        output = torch.abs(output1 - output2)
        output = self.fc2(output)
        return output


def read_directory(files, w, h):
    idx = 0
    array_of_img = {}
    for f_name in files:
        array_of_img[idx] = []
        for img_name in os.listdir(path + '/' + f_name):
            img = cv2.imread(path + '/' + f_name + '/' + img_name)
            img = cv2.resize(img, (w, h))
            img = img.transpose((2, 0, 1))
            array_of_img[idx].append(img)
        idx += 1
    return array_of_img


path = 'C:/Users/jack8/Desktop/Mid_Project/virusimage'
files = os.listdir(path)
w = 64 #寬
h = 64 #高
array_of_img = read_directory(files, w, h)

total_sample_size = 840 #同類別及不同類別各形成980組
class_num = 7 #訓練之類別數
train_num = 20 #每類別之訓練樣本數


def get_data(array_of_img, total_sample_size):

    pick_img = array_of_img[0][0]
    #提取圖片大小
    dim1 = pick_img.shape[1]
    dim2 = pick_img.shape[2]

    count = 0
    #初始化一nparray[total_sample, no_of_pairs, dim1, dim2]
    x_genuine_pair = np.zeros([total_sample_size, 2, 3, dim1, dim2]) # 2為一對照片
    y_genuine = np.zeros([total_sample_size, 1])
 
    for i in range(class_num):
        for j in range(int(total_sample_size/class_num)):
            ind1 = 0
            ind2 = 0
 
            #選取相同類別圖片 (genuine pair)
            while ind1 == ind2:
                ind1 = np.random.randint(train_num)
                ind2 = np.random.randint(train_num)
 
            #讀取兩張圖片
            img1 = array_of_img[i][ind1]
            img2 = array_of_img[i][ind2]
 
            #儲存至初始化之nparray
            x_genuine_pair[count, 0, :, :, :] = img1
            x_genuine_pair[count, 1, :, :, :] = img2
 
            #將相同類別之label標為1 (genuine pair)
            y_genuine[count] = 1
            count += 1
 
    count = 0
    #初始化一nparray[total_sample, no_of_pairs, dim1, dim2]
    x_imposite_pair = np.zeros([total_sample_size, 2, 3, dim1, dim2])
    y_imposite = np.zeros([total_sample_size, 1])
 
    for i in range(int(total_sample_size/train_num)):
        for j in range(train_num):
 
            #選取不同類別圖片 (imposite pair)
            while True:
                ind1 = np.random.randint(class_num)
                ind2 = np.random.randint(class_num)
                if ind1 != ind2:
                    break
            
            #讀取兩張圖片
            img1 = array_of_img[ind1][j]
            img2 = array_of_img[ind2][j]

            #儲存至初始化之nparray
            x_imposite_pair[count, 0, :, :, :] = img1
            x_imposite_pair[count, 1, :, :, :] = img2

            #將相同類別之label標為0 (imposite pair)
            y_imposite[count] = 0
            count += 1
 
    #將genuine pairs和imposite pair合併在一起
    X = np.concatenate([x_genuine_pair, x_imposite_pair], axis=0)/255
    Y = np.concatenate([y_genuine, y_imposite], axis=0)
 
    return X, Y

X, Y = get_data(array_of_img, total_sample_size) #X為同類別組合及不同類別組合，Y為同類別組合之標籤及不同類別之標籤

class TraindataSet(Dataset):
    #資料整理
    def __init__(self,train_1,train_2,train_labels):
        self.img1_data = train_1
        self.img2_data = train_2
        self.label_data = train_labels
        self.len = len(train_labels)

    def __getitem__(self,index):
        return self.img1_data[index],self.img2_data[index],self.label_data[index]

    def __len__(self):
        return self.len


def get_k_fold_data(k, i, X, y):
    # 返回第i折交叉驗證時所需要的訓練和驗證數據，分開放，X_train為訓練數據，X_valid為驗證數據

    fold_size = X.shape[0] // k # 每份的個數:數據總條數/折數（組數）
    
    X_train, y_train = None, None
    for j in range(k):
        idx = slice(j * fold_size, (j + 1) * fold_size) #slice(start,end,step)切片函數
        #idx 為每組valid
        X_part, y_part = X[idx, :], y[idx]
        if j == i: #第i折作valid
            X_valid, y_valid = X_part, y_part
        elif X_train is None:
            X_train, y_train = X_part, y_part
        else:
            X_train = np.concatenate((X_train, X_part), axis=0) #dim=0增加行數，垂直連接
            y_train = np.concatenate((y_train, y_part), axis=0)
    
    return X_train, y_train, X_valid, y_valid

# from sklearn.model_selection import train_test_split
# x_train, x_cv, y_train, y_cv = train_test_split(X, Y, test_size=0.1)

def shuffle_data(data):
    #資料重新排序
    img_t = data[0][:]
    label_t = data[1]

    index_t = [i for i in range(len(img_t))] 
    random.shuffle(index_t)
    img_t = img_t[index_t]
    label_t = label_t[index_t]


    img_v = data[2][:]
    label_v = data[3]

    index_v = [j for j in range(len(img_v))] 
    random.shuffle(index_v)
    img_v = img_v[index_v]
    label_v = label_v[index_v]

    return img_t, label_t, img_v, label_v


def Train(ith, img_t1, img_t2, label_t, img_v1, img_v2, label_v, net, optimizer, criterion, epochs, batch_size):
    #訓練及驗證
    net.train()

    dataset = TraindataSet(train_1=img_t1, train_2=img_t2, train_labels=label_t)
    train_dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)

    dataset_v = TraindataSet(train_1=img_v1, train_2=img_v2, train_labels=label_v)
    cv_dataloader = DataLoader(dataset_v, shuffle=False, batch_size=batch_size)

    counter = []
    loss_history = [] 
    iteration_number = 0
    val_losses = []
    train_acc = []
    val_acc = []
    K_fold_store = []

    #訓練
    for epoch in range(0, epochs):
        correct_t = 0
        error = 0
        pre = []
        for i, data in enumerate(train_dataloader, 0):
            img1, img2, label = data
            img1, img2, label = img1.cuda(), img2.cuda(), label.cuda()
            optimizer.zero_grad()
            output = net.forward(img1.float(), img2.float())
            losses = criterion(output.to(torch.float64), label)
            losses.backward()
            optimizer.step()
            if i % 100 == 0:
                iteration_number += 100
                counter.append(iteration_number)
                loss_history.append(losses.item())
            
            for i in range(len(label)):
                if output[i].item() >= 0.5: 
                    pre.append(1)
                    if pre[i] == label[i].item():
                        correct_t += 1
                    else: 
                        error += 1
                elif output[i].item() < 0.5: 
                    pre.append(0)
                    if pre[i] == label[i].item():
                        correct_t += 1
                    else: 
                        error += 1

            # correct_t += pred.eq(label.view_as(pred)).sum().item() #測試訓練集
        print("Epoch : {} / {} , Current loss: {:.5f}\n".format(epoch+1, epochs, losses.item()))

        accuracy = 100.*correct_t/len(img_t1)
        train_acc.append(accuracy)


        #驗證
        net.eval()
        val_loss = 0
        correct_v = 0
        error_v = 0
        pre_v = []
        with torch.no_grad():
            for i, data in enumerate(cv_dataloader, 0):
                img1, img2, label = data
                img1, img2, label = img1.cuda(), img2.cuda(), label.cuda()
                output = net(img1.float(), img2.float())
                # losses = criterion(output, label)
                

                for i in range(len(label)):
                    if output[i].item() >= 0.5: 
                        pre_v.append(1)
                        if pre_v[i] == label[i].item():
                            correct_v += 1
                        else: 
                            error_v += 1
                    elif output[i].item() < 0.5: 
                        pre_v.append(0)
                        if pre_v[i] == label[i].item():
                            correct_v += 1
                        else: 
                            error_v += 1

                # correct_v += pred.eq(label.view_as(pred)).sum().item() #測試驗證集
            # print(correct_t)
        # val_losses.append(val_loss/len(img_v1))
        accuracy = 100.*correct_v/len(img_v1)
        val_acc.append(accuracy)
        
        # K_fold_store.append(val_losses[-1])
        K_fold_store.append(loss_history[-1])

    if K_fold_store is None: #存取模型
        torch.save(net, 'C:/Users/jack8/Desktop/Mid_Project/model/model_SiameseNet' + str(ith) +'.pth')
    elif K_fold_store[-1] < K_fold_store[-2]:
        torch.save(net, 'C:/Users/jack8/Desktop/Mid_Project/model/model_SiameseNet' + str(ith) +'.pth')

        # if losses.item() < 0.02:
        #     torch.save(net.state_dict(), ('../model/model_SiameseNet'+str(epoch)+'.pth'))

    # print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\n'.format(val_loss, correct_v, len(label_v), accuracy))
    # print('Training set accuracy: {}/{} ({:.3f}%)'.format(correct_t, len(label_t), accuracy))

    # show_plot(counter, loss_history)

    return loss_history, val_losses, train_acc, val_acc


def K_fold(k, X, Y, net, optimizer, criterion, epochs, batch_size): #K_fold交叉驗證
    train_loss_sum, valid_loss_sum = 0, 0
    train_acc_sum , valid_acc_sum = 0, 0

    for i in range(k):   #第i折作valid
        k_fold_data = get_k_fold_data(k, i, X, Y) #取得K折data
        img_t, label_t, img_v, label_v = shuffle_data(k_fold_data) #將data及label打亂
        img_t1 = img_t[:,0]
        img_t2 = img_t[:,1]
        img_v1 = img_v[:,0]
        img_v2 = img_v[:,1]
        loss_history, val_losses, train_acc, val_acc = Train(i+1, img_t1, img_t2, label_t, img_v1, img_v2, label_v, 
                                                                    net, optimizer, criterion, epochs, batch_size)

        # print('train_loss:{:.5f}, train_acc:{:.3f}%'.format(loss_history[-1], train_acc[-1]))
        print('valid_acc:{:.3f}%\n'.format(val_acc[-1]))
        # print('valid_loss:{:.5f}, valid_acc:{:.3f}%\n'.format(val_losses[-1], val_acc[-1]))
        
        train_loss_sum += loss_history[-1]
        # valid_loss_sum += val_losses[-1]
        train_acc_sum += train_acc[-1]
        valid_acc_sum += val_acc[-1]
        
    print('\n', '#'*10,'最終k折交叉驗證結果','#'*10) 
    

    # print('average train loss:{:.4f}, average train accuracy:{:.3f}%'.format(train_loss_sum/k, train_acc_sum/k))
    print('average valid accuracy:{:.3f}%'.format(valid_acc_sum/k))
    # print('average valid loss:{:.4f}, average valid accuracy:{:.3f}%'.format(valid_loss_sum/k, valid_acc_sum/k))

    # print('average train loss:{:.4f}, average valid accuracy:{:.3f}%'.format(train_loss_sum/k, valid_acc_sum/k))

    return


net = SiameseNetwork().cuda() #定義模型且移至GPU
criterion = torch.nn.BCELoss() #定義損失函式
optimizer = optim.Adam(net.parameters(), lr = 0.001) #定義最佳化器

k = 10 #K折
epochs = 15
batch_size = 64

K_fold(k, X, Y, net, optimizer, criterion, epochs, batch_size)